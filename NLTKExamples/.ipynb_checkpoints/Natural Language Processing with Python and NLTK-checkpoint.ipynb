{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tokanize [Words/Senstenses]: Splitting the sentense.\n",
    "* Lexicon: Words-> Meaning (dictionary). Vocabulary.\n",
    "* Corpora: Body of text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"\"\"Apparently, Ernest Hemingway was lunching at Luchow's with a number of writers and claimed \\\n",
    "that he could write a short story that was only six words long. Of course, the other writers balked. \\\n",
    "Hemingway told each of them to put ten dollars in the middle of the table; if he was wrong, he said, \\\n",
    "he’d match it. If he was right, he would keep the entire pot. He quickly wrote six words down on a \\\n",
    "napkin and passed it around; Papa won the bet. The words were \"FOR SALE, BABY SHOES, NEVER WORN.\" \\\n",
    "A beginning, a middle and an end!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokanaizing Words and Sentenses\n",
    "* In word tokenize, puntuation characters [.,?!;'\"] identifies as a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Apparently, Ernest Hemingway was lunching at Luchow's with a number of writers and claimed that he could write a short story that was only six words long.\", 'Of course, the other writers balked.', 'Hemingway told each of them to put ten dollars in the middle of the table; if he was wrong, he said, he’d match it.', 'If he was right, he would keep the entire pot.', 'He quickly wrote six words down on a napkin and passed it around; Papa won the bet.', 'The words were \"FOR SALE, BABY SHOES, NEVER WORN.\"', 'A beginning, a middle and an end!']\n"
     ]
    }
   ],
   "source": [
    "Sentences = nltk.sent_tokenize(Text)   \n",
    "print(Sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apparently', ',', 'Ernest', 'Hemingway', 'was', 'lunching', 'at', 'Luchow', \"'s\", 'with', 'a', 'number', 'of', 'writers', 'and', 'claimed', 'that', 'he', 'could', 'write', 'a', 'short', 'story', 'that', 'was', 'only', 'six', 'words', 'long', '.', 'Of', 'course', ',', 'the', 'other', 'writers', 'balked', '.', 'Hemingway', 'told', 'each', 'of', 'them', 'to', 'put', 'ten', 'dollars', 'in', 'the', 'middle', 'of', 'the', 'table', ';', 'if', 'he', 'was', 'wrong', ',', 'he', 'said', ',', 'he', '’', 'd', 'match', 'it', '.', 'If', 'he', 'was', 'right', ',', 'he', 'would', 'keep', 'the', 'entire', 'pot', '.', 'He', 'quickly', 'wrote', 'six', 'words', 'down', 'on', 'a', 'napkin', 'and', 'passed', 'it', 'around', ';', 'Papa', 'won', 'the', 'bet', '.', 'The', 'words', 'were', '``', 'FOR', 'SALE', ',', 'BABY', 'SHOES', ',', 'NEVER', 'WORN', '.', \"''\", 'A', 'beginning', ',', 'a', 'middle', 'and', 'an', 'end', '!']\n"
     ]
    }
   ],
   "source": [
    "Words = nltk.word_tokenize(Text)\n",
    "print(Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hadn't\", \"wouldn't\", 'we', 'being', 'below', 'during', 'them', 'aren', 'their', 'its', 'a', 's', 'too', 'then', 'ma', 'on', 'against', 'after', 'why', 'shan', \"she's\", 'been', 'do', 'or', 'who', 'any', 'from', 'no', 'all', 'under', 're', \"mustn't\", 't', 'were', 'other', 'an', \"shan't\", 'hadn', 'own', 'doesn', 'themselves', 'can', 'don', 'for', \"mightn't\", 'have', 'here', 'ourselves', 'haven', 'isn', \"should've\", 'ours', 'am', \"doesn't\", 'while', 'she', 'he', 'it', 'his', 'where', 'mustn', 'does', 'wouldn', 'myself', 'yourself', 'most', 'just', 'they', 'such', 'hers', 'o', 'ain', \"isn't\", 'down', 'yourselves', 'to', \"don't\", 'herself', 'than', 'has', 'nor', 'having', 'the', 'more', \"needn't\", 'whom', 'y', 'up', 'should', \"won't\", 'my', 'as', 'will', 'didn', 'now', 'over', 'into', 'through', 'yours', 'but', 'each', 'itself', 'what', \"didn't\", 'by', 'same', 'shouldn', 'll', 'off', \"you'd\", 'be', 'himself', 'there', 'once', 'needn', 'before', 'again', 'not', 'that', 'because', 'further', \"weren't\", 'very', \"hasn't\", 'at', 'out', \"that'll\", 'your', 'did', 'about', 'was', 'these', 'until', \"shouldn't\", 'hasn', 'are', 'only', 'this', 'mightn', 'with', 'which', 'me', \"it's\", 'few', 'those', 'so', 'wasn', \"you've\", 'between', 'won', 'had', 'him', 'weren', \"you'll\", 'is', 'doing', \"couldn't\", \"you're\", 'how', 'some', 'both', 've', \"haven't\", 'when', 'of', 'd', 'i', 'couldn', \"aren't\", 'you', 'our', 'above', 'm', \"wasn't\", 'theirs', 'her', 'and', 'if', 'in'}\n"
     ]
    }
   ],
   "source": [
    "StopWords = set(nltk.corpus.stopwords.words('english'))\n",
    "print(StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apparently', ',', 'Ernest', 'Hemingway', 'lunching', 'Luchow', \"'s\", 'number', 'writers', 'claimed', 'could', 'write', 'short', 'story', 'six', 'words', 'long', '.', 'Of', 'course', ',', 'writers', 'balked', '.', 'Hemingway', 'told', 'put', 'ten', 'dollars', 'middle', 'table', ';', 'wrong', ',', 'said', ',', '’', 'match', '.', 'If', 'right', ',', 'would', 'keep', 'entire', 'pot', '.', 'He', 'quickly', 'wrote', 'six', 'words', 'napkin', 'passed', 'around', ';', 'Papa', 'bet', '.', 'The', 'words', '``', 'FOR', 'SALE', ',', 'BABY', 'SHOES', ',', 'NEVER', 'WORN', '.', \"''\", 'A', 'beginning', ',', 'middle', 'end', '!']\n"
     ]
    }
   ],
   "source": [
    "WordsFiltered = []\n",
    "\n",
    "for w in Words:\n",
    "    if w not in StopWords:\n",
    "        WordsFiltered.append(w)\n",
    "        \n",
    "print(WordsFiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apparently -> appar\n",
      ", -> ,\n",
      "Ernest -> ernest\n",
      "Hemingway -> hemingway\n",
      "was -> wa\n",
      "lunching -> lunch\n",
      "at -> at\n",
      "Luchow -> luchow\n",
      "'s -> 's\n",
      "with -> with\n",
      "a -> a\n",
      "number -> number\n",
      "of -> of\n",
      "writers -> writer\n",
      "and -> and\n",
      "claimed -> claim\n",
      "that -> that\n",
      "he -> he\n",
      "could -> could\n",
      "write -> write\n",
      "a -> a\n",
      "short -> short\n",
      "story -> stori\n",
      "that -> that\n",
      "was -> wa\n",
      "only -> onli\n",
      "six -> six\n",
      "words -> word\n",
      "long -> long\n",
      ". -> .\n",
      "Of -> Of\n",
      "course -> cours\n",
      ", -> ,\n",
      "the -> the\n",
      "other -> other\n",
      "writers -> writer\n",
      "balked -> balk\n",
      ". -> .\n",
      "Hemingway -> hemingway\n",
      "told -> told\n",
      "each -> each\n",
      "of -> of\n",
      "them -> them\n",
      "to -> to\n",
      "put -> put\n",
      "ten -> ten\n",
      "dollars -> dollar\n",
      "in -> in\n",
      "the -> the\n",
      "middle -> middl\n",
      "of -> of\n",
      "the -> the\n",
      "table -> tabl\n",
      "; -> ;\n",
      "if -> if\n",
      "he -> he\n",
      "was -> wa\n",
      "wrong -> wrong\n",
      ", -> ,\n",
      "he -> he\n",
      "said -> said\n",
      ", -> ,\n",
      "he -> he\n",
      "’ -> ’\n",
      "d -> d\n",
      "match -> match\n",
      "it -> it\n",
      ". -> .\n",
      "If -> If\n",
      "he -> he\n",
      "was -> wa\n",
      "right -> right\n",
      ", -> ,\n",
      "he -> he\n",
      "would -> would\n",
      "keep -> keep\n",
      "the -> the\n",
      "entire -> entir\n",
      "pot -> pot\n",
      ". -> .\n",
      "He -> He\n",
      "quickly -> quickli\n",
      "wrote -> wrote\n",
      "six -> six\n",
      "words -> word\n",
      "down -> down\n",
      "on -> on\n",
      "a -> a\n",
      "napkin -> napkin\n",
      "and -> and\n",
      "passed -> pass\n",
      "it -> it\n",
      "around -> around\n",
      "; -> ;\n",
      "Papa -> papa\n",
      "won -> won\n",
      "the -> the\n",
      "bet -> bet\n",
      ". -> .\n",
      "The -> the\n",
      "words -> word\n",
      "were -> were\n",
      "`` -> ``\n",
      "FOR -> for\n",
      "SALE -> sale\n",
      ", -> ,\n",
      "BABY -> babi\n",
      "SHOES -> shoe\n",
      ", -> ,\n",
      "NEVER -> never\n",
      "WORN -> worn\n",
      ". -> .\n",
      "'' -> ''\n",
      "A -> A\n",
      "beginning -> begin\n",
      ", -> ,\n",
      "a -> a\n",
      "middle -> middl\n",
      "and -> and\n",
      "an -> an\n",
      "end -> end\n",
      "! -> !\n",
      "['appar', ',', 'ernest', 'hemingway', 'wa', 'lunch', 'at', 'luchow', \"'s\", 'with', 'a', 'number', 'of', 'writer', 'and', 'claim', 'that', 'he', 'could', 'write', 'a', 'short', 'stori', 'that', 'wa', 'onli', 'six', 'word', 'long', '.', 'Of', 'cours', ',', 'the', 'other', 'writer', 'balk', '.', 'hemingway', 'told', 'each', 'of', 'them', 'to', 'put', 'ten', 'dollar', 'in', 'the', 'middl', 'of', 'the', 'tabl', ';', 'if', 'he', 'wa', 'wrong', ',', 'he', 'said', ',', 'he', '’', 'd', 'match', 'it', '.', 'If', 'he', 'wa', 'right', ',', 'he', 'would', 'keep', 'the', 'entir', 'pot', '.', 'He', 'quickli', 'wrote', 'six', 'word', 'down', 'on', 'a', 'napkin', 'and', 'pass', 'it', 'around', ';', 'papa', 'won', 'the', 'bet', '.', 'the', 'word', 'were', '``', 'for', 'sale', ',', 'babi', 'shoe', ',', 'never', 'worn', '.', \"''\", 'A', 'begin', ',', 'a', 'middl', 'and', 'an', 'end', '!']\n"
     ]
    }
   ],
   "source": [
    "PS = nltk.stem.PorterStemmer()\n",
    "\n",
    "WordsStemmed = []\n",
    "\n",
    "for w in Words:\n",
    "    sw = PS.stem(w)\n",
    "    WordsStemmed.append(sw)\n",
    "    print('{} -> {}'.format(w,sw))\n",
    "\n",
    "print(WordsStemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apparently', 'RB'), (',', ','), ('Ernest', 'NNP'), ('Hemingway', 'NNP'), ('was', 'VBD'), ('lunching', 'VBG'), ('at', 'IN'), ('Luchow', 'NNP'), (\"'s\", 'POS'), ('with', 'IN'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('writers', 'NNS'), ('and', 'CC'), ('claimed', 'VBD'), ('that', 'IN'), ('he', 'PRP'), ('could', 'MD'), ('write', 'VB'), ('a', 'DT'), ('short', 'JJ'), ('story', 'NN'), ('that', 'WDT'), ('was', 'VBD'), ('only', 'RB'), ('six', 'CD'), ('words', 'NNS'), ('long', 'RB'), ('.', '.'), ('Of', 'IN'), ('course', 'NN'), (',', ','), ('the', 'DT'), ('other', 'JJ'), ('writers', 'NNS'), ('balked', 'VBD'), ('.', '.'), ('Hemingway', 'NNP'), ('told', 'VBD'), ('each', 'DT'), ('of', 'IN'), ('them', 'PRP'), ('to', 'TO'), ('put', 'VB'), ('ten', 'RP'), ('dollars', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('middle', 'NN'), ('of', 'IN'), ('the', 'DT'), ('table', 'NN'), (';', ':'), ('if', 'IN'), ('he', 'PRP'), ('was', 'VBD'), ('wrong', 'RB'), (',', ','), ('he', 'PRP'), ('said', 'VBD'), (',', ','), ('he', 'PRP'), ('’', 'VBZ'), ('d', 'JJ'), ('match', 'NN'), ('it', 'PRP'), ('.', '.'), ('If', 'IN'), ('he', 'PRP'), ('was', 'VBD'), ('right', 'RB'), (',', ','), ('he', 'PRP'), ('would', 'MD'), ('keep', 'VB'), ('the', 'DT'), ('entire', 'JJ'), ('pot', 'NN'), ('.', '.'), ('He', 'PRP'), ('quickly', 'RB'), ('wrote', 'VBD'), ('six', 'CD'), ('words', 'NNS'), ('down', 'RP'), ('on', 'IN'), ('a', 'DT'), ('napkin', 'JJ'), ('and', 'CC'), ('passed', 'VBD'), ('it', 'PRP'), ('around', 'RP'), (';', ':'), ('Papa', 'NNP'), ('won', 'VBD'), ('the', 'DT'), ('bet', 'NN'), ('.', '.'), ('The', 'DT'), ('words', 'NNS'), ('were', 'VBD'), ('``', '``'), ('FOR', 'NNP'), ('SALE', 'NNP'), (',', ','), ('BABY', 'NNP'), ('SHOES', 'NNP'), (',', ','), ('NEVER', 'NNP'), ('WORN', 'NNP'), ('.', '.'), (\"''\", \"''\"), ('A', 'DT'), ('beginning', 'NN'), (',', ','), ('a', 'DT'), ('middle', 'NN'), ('and', 'CC'), ('an', 'DT'), ('end', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "POSTags = nltk.pos_tag(Words)\n",
    "print(POSTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(nltk.help.upenn_tagset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chuncking and Chinking\n",
    "* Chuncking: Extract portions in a given liguistic pattern.\n",
    "* Chinking: Removing/exclude portions in a given liguistic pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Apparently/RB\n",
      "  ,/,\n",
      "  (PERSON Ernest/NNP Hemingway/NNP)\n",
      "  was/VBD\n",
      "  lunching/VBG\n",
      "  at/IN\n",
      "  (ORGANIZATION Luchow/NNP)\n",
      "  's/POS\n",
      "  with/IN\n",
      "  a/DT\n",
      "  number/NN\n",
      "  of/IN\n",
      "  writers/NNS\n",
      "  and/CC\n",
      "  claimed/VBD\n",
      "  that/IN\n",
      "  he/PRP\n",
      "  could/MD\n",
      "  write/VB\n",
      "  a/DT\n",
      "  short/JJ\n",
      "  story/NN\n",
      "  that/WDT\n",
      "  was/VBD\n",
      "  only/RB\n",
      "  six/CD\n",
      "  words/NNS\n",
      "  long/RB\n",
      "  ./.\n",
      "  Of/IN\n",
      "  course/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  other/JJ\n",
      "  writers/NNS\n",
      "  balked/VBD\n",
      "  ./.\n",
      "  (PERSON Hemingway/NNP)\n",
      "  told/VBD\n",
      "  each/DT\n",
      "  of/IN\n",
      "  them/PRP\n",
      "  to/TO\n",
      "  put/VB\n",
      "  ten/RP\n",
      "  dollars/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  middle/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  table/NN\n",
      "  ;/:\n",
      "  if/IN\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  wrong/RB\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  said/VBD\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  ’/VBZ\n",
      "  d/JJ\n",
      "  match/NN\n",
      "  it/PRP\n",
      "  ./.\n",
      "  If/IN\n",
      "  he/PRP\n",
      "  was/VBD\n",
      "  right/RB\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  would/MD\n",
      "  keep/VB\n",
      "  the/DT\n",
      "  entire/JJ\n",
      "  pot/NN\n",
      "  ./.\n",
      "  He/PRP\n",
      "  quickly/RB\n",
      "  wrote/VBD\n",
      "  six/CD\n",
      "  words/NNS\n",
      "  down/RP\n",
      "  on/IN\n",
      "  a/DT\n",
      "  napkin/JJ\n",
      "  and/CC\n",
      "  passed/VBD\n",
      "  it/PRP\n",
      "  around/RP\n",
      "  ;/:\n",
      "  (PERSON Papa/NNP)\n",
      "  won/VBD\n",
      "  the/DT\n",
      "  bet/NN\n",
      "  ./.\n",
      "  The/DT\n",
      "  words/NNS\n",
      "  were/VBD\n",
      "  ``/``\n",
      "  (ORGANIZATION FOR/NNP SALE/NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION BABY/NNP)\n",
      "  SHOES/NNP\n",
      "  ,/,\n",
      "  (ORGANIZATION NEVER/NNP)\n",
      "  WORN/NNP\n",
      "  ./.\n",
      "  ''/''\n",
      "  A/DT\n",
      "  beginning/NN\n",
      "  ,/,\n",
      "  a/DT\n",
      "  middle/NN\n",
      "  and/CC\n",
      "  an/DT\n",
      "  end/NN\n",
      "  !/.)\n"
     ]
    }
   ],
   "source": [
    "NamedEntity = nltk.ne_chunk(POSTags)\n",
    "print(NamedEntity)\n",
    "NamedEntity.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "* Lemmas\n",
    "* Synonyms\n",
    "* Antonyms\n",
    "* Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
